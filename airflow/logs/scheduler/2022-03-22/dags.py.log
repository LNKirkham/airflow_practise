[2022-03-22 09:53:54,431] {processor.py:163} INFO - Started process (PID=84063) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 09:53:54,431] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 09:53:54,431] {logging_mixin.py:109} INFO - [2022-03-22 09:53:54,431] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 09:54:03,238] {logging_mixin.py:109} INFO - [2022-03-22 09:54:03,228] {dagbag.py:334} ERROR - Failed to import: /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
Traceback (most recent call last):
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow_env/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py", line 36, in <module>
    etl()
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py", line 9, in etl
    movies_df = extract_movies_to_df()
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/transformation.py", line 13, in extract_movies_to_df
    movies_df = spark.read \
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow_env/lib/python3.9/site-packages/pyspark/sql/readwriter.py", line 164, in load
    return self._df(self._jreader.load())
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow_env/lib/python3.9/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow_env/lib/python3.9/site-packages/pyspark/sql/utils.py", line 111, in deco
    return f(*a, **kw)
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow_env/lib/python3.9/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o36.load.
: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)
	at org.postgresql.Driver.makeConnection(Driver.java:400)
	at org.postgresql.Driver.connect(Driver.java:259)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:62)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:57)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:239)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:36)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:567)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:830)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:579)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:339)
	at java.base/java.net.Socket.connect(Socket.java:603)
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241)
	at org.postgresql.core.PGStream.<init>(PGStream.java:98)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	... 29 more
[2022-03-22 09:54:03,267] {processor.py:690} INFO - Deactivated 1 DAGs which are no longer present in /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 09:54:03,267] {processor.py:656} WARNING - No viable dags retrieved from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 09:54:03,273] {processor.py:171} INFO - Processing /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py took 8.842 seconds
[2022-03-22 09:55:16,669] {processor.py:163} INFO - Started process (PID=84162) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 09:55:16,669] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 09:55:16,670] {logging_mixin.py:109} INFO - [2022-03-22 09:55:16,670] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 09:55:20,392] {logging_mixin.py:109} INFO - [2022-03-22 09:55:20,390] {dagbag.py:334} ERROR - Failed to import: /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
Traceback (most recent call last):
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow_env/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py", line 36, in <module>
    etl()
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py", line 9, in etl
    movies_df = extract_movies_to_df()
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/transformation.py", line 13, in extract_movies_to_df
    movies_df = spark.read \
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow_env/lib/python3.9/site-packages/pyspark/sql/readwriter.py", line 164, in load
    return self._df(self._jreader.load())
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow_env/lib/python3.9/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow_env/lib/python3.9/site-packages/pyspark/sql/utils.py", line 111, in deco
    return f(*a, **kw)
  File "/Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow_env/lib/python3.9/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o36.load.
: org.postgresql.util.PSQLException: Connection to localhost:5432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:319)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:49)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)
	at org.postgresql.Driver.makeConnection(Driver.java:400)
	at org.postgresql.Driver.connect(Driver.java:259)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)
	at org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProvider$.create(ConnectionProvider.scala:77)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$createConnectionFactory$1(JdbcUtils.scala:64)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:62)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:57)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:239)
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:36)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:274)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$3(DataFrameReader.scala:245)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:245)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:567)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:830)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:579)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:339)
	at java.base/java.net.Socket.connect(Socket.java:603)
	at org.postgresql.core.PGStream.createSocket(PGStream.java:241)
	at org.postgresql.core.PGStream.<init>(PGStream.java:98)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:109)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:235)
	... 29 more
[2022-03-22 09:55:20,414] {processor.py:656} WARNING - No viable dags retrieved from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 09:55:20,418] {processor.py:171} INFO - Processing /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py took 3.749 seconds
[2022-03-22 10:05:51,186] {processor.py:163} INFO - Started process (PID=84270) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:05:51,186] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 10:05:51,186] {logging_mixin.py:109} INFO - [2022-03-22 10:05:51,186] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:06:04,378] {processor.py:654} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:06:04,596] {logging_mixin.py:109} INFO - [2022-03-22 10:06:04,596] {dag.py:2398} INFO - Sync 1 DAGs
[2022-03-22 10:06:04,606] {logging_mixin.py:109} INFO - [2022-03-22 10:06:04,606] {dag.py:2937} INFO - Setting next_dagrun for etl_pipeline to 2022-03-21T00:00:00+00:00
[2022-03-22 10:06:04,615] {processor.py:171} INFO - Processing /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py took 13.431 seconds
[2022-03-22 10:06:44,422] {processor.py:163} INFO - Started process (PID=84404) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:06:44,422] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 10:06:44,423] {logging_mixin.py:109} INFO - [2022-03-22 10:06:44,423] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:06:53,753] {processor.py:654} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:06:53,778] {logging_mixin.py:109} INFO - [2022-03-22 10:06:53,778] {dag.py:2398} INFO - Sync 1 DAGs
[2022-03-22 10:06:53,795] {logging_mixin.py:109} INFO - [2022-03-22 10:06:53,794] {dag.py:2937} INFO - Setting next_dagrun for etl_pipeline to 2022-03-21T00:00:00+00:00
[2022-03-22 10:06:53,803] {processor.py:171} INFO - Processing /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py took 9.382 seconds
[2022-03-22 10:07:31,647] {processor.py:163} INFO - Started process (PID=84460) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:07:31,647] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 10:07:31,648] {logging_mixin.py:109} INFO - [2022-03-22 10:07:31,648] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:07:40,941] {processor.py:654} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:07:40,959] {logging_mixin.py:109} INFO - [2022-03-22 10:07:40,959] {dag.py:2398} INFO - Sync 1 DAGs
[2022-03-22 10:07:40,972] {logging_mixin.py:109} INFO - [2022-03-22 10:07:40,972] {dag.py:2937} INFO - Setting next_dagrun for etl_pipeline to 2022-03-21T00:00:00+00:00
[2022-03-22 10:07:40,981] {processor.py:171} INFO - Processing /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py took 9.334 seconds
[2022-03-22 10:08:19,733] {processor.py:163} INFO - Started process (PID=84506) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:08:19,734] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 10:08:19,734] {logging_mixin.py:109} INFO - [2022-03-22 10:08:19,734] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:08:28,222] {processor.py:654} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:08:28,246] {logging_mixin.py:109} INFO - [2022-03-22 10:08:28,245] {dag.py:2398} INFO - Sync 1 DAGs
[2022-03-22 10:08:28,261] {logging_mixin.py:109} INFO - [2022-03-22 10:08:28,260] {dag.py:2937} INFO - Setting next_dagrun for etl_pipeline to 2022-03-21T00:00:00+00:00
[2022-03-22 10:08:28,270] {processor.py:171} INFO - Processing /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py took 8.537 seconds
[2022-03-22 10:09:04,673] {processor.py:163} INFO - Started process (PID=84556) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:09:04,673] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 10:09:04,674] {logging_mixin.py:109} INFO - [2022-03-22 10:09:04,674] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:09:13,119] {processor.py:654} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:09:13,140] {logging_mixin.py:109} INFO - [2022-03-22 10:09:13,140] {dag.py:2398} INFO - Sync 1 DAGs
[2022-03-22 10:09:13,155] {logging_mixin.py:109} INFO - [2022-03-22 10:09:13,155] {dag.py:2937} INFO - Setting next_dagrun for etl_pipeline to 2022-03-21T00:00:00+00:00
[2022-03-22 10:09:13,163] {processor.py:171} INFO - Processing /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py took 8.491 seconds
[2022-03-22 10:09:49,312] {processor.py:163} INFO - Started process (PID=84996) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:09:49,313] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 10:09:49,313] {logging_mixin.py:109} INFO - [2022-03-22 10:09:49,313] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:09:56,992] {processor.py:654} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:09:57,008] {logging_mixin.py:109} INFO - [2022-03-22 10:09:57,007] {dag.py:2398} INFO - Sync 1 DAGs
[2022-03-22 10:09:57,017] {logging_mixin.py:109} INFO - [2022-03-22 10:09:57,017] {dag.py:2937} INFO - Setting next_dagrun for etl_pipeline to 2022-03-21T00:00:00+00:00
[2022-03-22 10:09:57,025] {processor.py:171} INFO - Processing /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py took 7.713 seconds
[2022-03-22 10:10:33,289] {processor.py:163} INFO - Started process (PID=85101) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:10:33,289] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 10:10:33,289] {logging_mixin.py:109} INFO - [2022-03-22 10:10:33,289] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:10:40,952] {processor.py:654} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:10:40,969] {logging_mixin.py:109} INFO - [2022-03-22 10:10:40,969] {dag.py:2398} INFO - Sync 1 DAGs
[2022-03-22 10:10:40,980] {logging_mixin.py:109} INFO - [2022-03-22 10:10:40,979] {dag.py:2937} INFO - Setting next_dagrun for etl_pipeline to 2022-03-21T00:00:00+00:00
[2022-03-22 10:10:40,987] {processor.py:171} INFO - Processing /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py took 7.698 seconds
[2022-03-22 10:11:17,449] {processor.py:163} INFO - Started process (PID=85169) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:11:17,449] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 10:11:17,449] {logging_mixin.py:109} INFO - [2022-03-22 10:11:17,449] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:11:25,265] {processor.py:654} INFO - DAG(s) dict_keys(['etl_pipeline']) retrieved from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:11:25,283] {logging_mixin.py:109} INFO - [2022-03-22 10:11:25,283] {dag.py:2398} INFO - Sync 1 DAGs
[2022-03-22 10:11:25,297] {logging_mixin.py:109} INFO - [2022-03-22 10:11:25,296] {dag.py:2937} INFO - Setting next_dagrun for etl_pipeline to 2022-03-21T00:00:00+00:00
[2022-03-22 10:11:25,304] {processor.py:171} INFO - Processing /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py took 7.857 seconds
[2022-03-22 10:12:14,510] {processor.py:163} INFO - Started process (PID=85848) to work on /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
[2022-03-22 10:12:14,511] {processor.py:642} INFO - Processing file /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py for tasks to queue
[2022-03-22 10:12:14,511] {logging_mixin.py:109} INFO - [2022-03-22 10:12:14,511] {dagbag.py:500} INFO - Filling up the DagBag from /Users/louisekirkham/Documents/linkedin_learning/Ex_Files_Data_Engineering_Foundations/airflow/dags/dags.py
